{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR Improved.ipynb","provenance":[],"authorship_tag":"ABX9TyMEu0sUPNCGvVnzW/kqaBp/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvSKqaAYcFR5","executionInfo":{"status":"ok","timestamp":1634057884254,"user_tz":-120,"elapsed":2631,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}},"outputId":"81079e62-252f-40f5-c335-431989ffb98a"},"source":["# Install TensorFlow\n","# !pip install -q tensorflow-gpu==2.0.0-beta1\n","\n","try:\n","  %tensorflow_version 2.x  # Colab only.\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n","\n","\n","TensorFlow 2.x selected.\n","2.6.0\n"]}]},{"cell_type":"code","metadata":{"id":"NkroyxGdcHER","executionInfo":{"status":"ok","timestamp":1634057885209,"user_tz":-120,"elapsed":959,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}}},"source":["# additional imports\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.models import Model"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTxZyBsUcIh_","executionInfo":{"status":"ok","timestamp":1634057894497,"user_tz":-120,"elapsed":6922,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}},"outputId":"fe1617d1-e391-4e93-c189-802ee5fc797c"},"source":["# Load in the data\n","cifar10 = tf.keras.datasets.cifar10\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","y_train, y_test = y_train.flatten(), y_test.flatten()\n","print(\"x_train.shape:\", x_train.shape)\n","print(\"y_train.shape\", y_train.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 3s 0us/step\n","170508288/170498071 [==============================] - 3s 0us/step\n","x_train.shape: (50000, 32, 32, 3)\n","y_train.shape (50000,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDcoWDPXcJ3u","executionInfo":{"status":"ok","timestamp":1634057895953,"user_tz":-120,"elapsed":249,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}},"outputId":"85a9b426-dc04-4b0f-d332-9eb7ccf6f455"},"source":["# number of classes\n","K = len(set(y_train))\n","print(\"number of classes:\", K)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["number of classes: 10\n"]}]},{"cell_type":"code","metadata":{"id":"yLaeKCPkcL2v","executionInfo":{"status":"ok","timestamp":1634057903768,"user_tz":-120,"elapsed":642,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}}},"source":["# Build the model using the functional API\n","i = Input(shape=x_train[0].shape)\n","# x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n","# x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n","# x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n","\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n","x = BatchNormalization()(x)\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2))(x)\n","# x = Dropout(0.2)(x)\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2))(x)\n","# x = Dropout(0.2)(x)\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2))(x)\n","# x = Dropout(0.2)(x)\n","\n","# x = GlobalMaxPooling2D()(x)\n","x = Flatten()(x)\n","x = Dropout(0.2)(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","x = Dense(K, activation='softmax')(x)\n","\n","model = Model(i, x)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfMgGSkGcNof","executionInfo":{"status":"ok","timestamp":1634057940000,"user_tz":-120,"elapsed":224,"user":{"displayName":"Tony Homsi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13762639256728607951"}}},"source":["# Compile\n","# Note: make sure you are using the GPU for this!\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"byej0-_LcWno"},"source":["# Fit\n","r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZvsx-BrcZKn"},"source":["# Fit with data augmentation\n","# Note: if you run this AFTER calling the previous model.fit(), it will CONTINUE training where it left off\n","batch_size = 32\n","data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n","train_generator = data_generator.flow(x_train, y_train, batch_size)\n","steps_per_epoch = x_train.shape[0] // batch_size\n","r = model.fit(train_generator, validation_data=(x_test, y_test), steps_per_epoch=steps_per_epoch, epochs=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3mDGqfefEKm"},"source":["# Plot loss per iteration\n","import matplotlib.pyplot as plt\n","plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnquS3m9fPlE"},"source":["# Plot accuracy per iteration\n","plt.plot(r.history['accuracy'], label='acc')\n","plt.plot(r.history['val_accuracy'], label='val_acc')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RuhI7TmfPnr"},"source":["# Plot confusion matrix\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","  \"\"\"\n","  This function prints and plots the confusion matrix.\n","  Normalization can be applied by setting `normalize=True`.\n","  \"\"\"\n","  if normalize:\n","      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","      print(\"Normalized confusion matrix\")\n","  else:\n","      print('Confusion matrix, without normalization')\n","\n","  print(cm)\n","\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  tick_marks = np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","\n","  fmt = '.2f' if normalize else 'd'\n","  thresh = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","      plt.text(j, i, format(cm[i, j], fmt),\n","               horizontalalignment=\"center\",\n","               color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","\n","\n","p_test = model.predict(x_test).argmax(axis=1)\n","cm = confusion_matrix(y_test, p_test)\n","plot_confusion_matrix(cm, list(range(10)))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxCC5drEfPqs"},"source":["# label mapping\n","labels = '''airplane\n","automobile\n","bird\n","cat\n","deer\n","dog\n","frog\n","horse\n","ship\n","truck'''.split()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNOQsl8bfPtt"},"source":["# Show some misclassified examples\n","misclassified_idx = np.where(p_test != y_test)[0]\n","i = np.random.choice(misclassified_idx)\n","plt.imshow(x_test[i], cmap='gray')\n","plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6zUtDY6fP3d"},"source":["# Now that the model is so large, it's useful to summarize it\n","model.summary()"],"execution_count":null,"outputs":[]}]}